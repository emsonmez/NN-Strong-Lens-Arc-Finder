{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660bfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.mast import Catalogs\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Extract SDSS DR18 LRG Samples using CasJobs\n",
    "# Data listed in dr18_lrg_sample.csv (Sample Size: 1,174,900)\n",
    "# Criteria : \n",
    "\n",
    "# SELECT\n",
    "  # s.specobjid,\n",
    "  # s.z AS redshift,                   \n",
    "  # s.veldisp,\n",
    "  # p.ra, p.dec, p.u, p.g, p.r, p.i, p.modelMag_r,\n",
    "  # s.programname, s.plate, s.fiberid, s.mjd into mydb.LRG_full_catalog from SpecObjAll AS s\n",
    "# JOIN PhotoObjAll AS p ON s.bestobjid = p.objid\n",
    "# WHERE\n",
    "  # s.class = 'GALAXY'\n",
    "  # AND s.z BETWEEN 0.1 AND 0.7\n",
    "  # AND s.veldisp > 0 AND s.veldisp < 500\n",
    "  # AND s.programname IN ('boss', 'eboss')\n",
    "  # AND (p.r - p.i) > 0.5\n",
    "  # AND (p.g - p.r) > 0.7\n",
    "  # AND p.modelMag_r BETWEEN 16 AND 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000\n",
    "INPUT_CSV = \"sdss_dr18_lrg_sample.csv\"\n",
    "OUTPUT_CSV_TEMPLATE = \"sdss_lrg_ps1_matched_batch_{batch_num}.csv\"\n",
    "OUTPUT_FOLDER = \"sdss_lrg_queried_objects\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "n_objects = len(df)\n",
    "\n",
    "def query_ps1_batch(batch_df):\n",
    "    g_mag, r_mag, i_mag = [], [], []\n",
    "    g_depth, r_depth, i_depth = [], [], []\n",
    "    g_fwhm, r_fwhm, i_fwhm = [], [], []\n",
    "\n",
    "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df)):\n",
    "        try:\n",
    "            coord = SkyCoord(ra=row['ra'], dec=row['dec'], unit='deg', frame='icrs')\n",
    "            result = Catalogs.query_region(coord, radius=2.5 * u.arcsec, catalog='PanSTARRS', data_release='dr2')\n",
    "            if len(result) > 0:\n",
    "                best = result[0]\n",
    "                g_mag.append(best.get('gMeanPSFMag'))\n",
    "                r_mag.append(best.get('rMeanPSFMag'))\n",
    "                i_mag.append(best.get('iMeanPSFMag'))\n",
    "\n",
    "                g_depth.append(best.get('gMeanDepth'))\n",
    "                r_depth.append(best.get('rMeanDepth'))\n",
    "                i_depth.append(best.get('iMeanDepth'))\n",
    "\n",
    "                g_fwhm.append(best.get('gFWHM'))\n",
    "                r_fwhm.append(best.get('rFWHM'))\n",
    "                i_fwhm.append(best.get('iFWHM'))\n",
    "            else:\n",
    "                g_mag.append(None)\n",
    "                r_mag.append(None)\n",
    "                i_mag.append(None)\n",
    "                g_depth.append(None)\n",
    "                r_depth.append(None)\n",
    "                i_depth.append(None)\n",
    "                g_fwhm.append(None)\n",
    "                r_fwhm.append(None)\n",
    "                i_fwhm.append(None)\n",
    "        except Exception:\n",
    "            g_mag.append(None)\n",
    "            r_mag.append(None)\n",
    "            i_mag.append(None)\n",
    "            g_depth.append(None)\n",
    "            r_depth.append(None)\n",
    "            i_depth.append(None)\n",
    "            g_fwhm.append(None)\n",
    "            r_fwhm.append(None)\n",
    "            i_fwhm.append(None)\n",
    "\n",
    "    batch_df['ps1_g_mag'] = g_mag\n",
    "    batch_df['ps1_r_mag'] = r_mag\n",
    "    batch_df['ps1_i_mag'] = i_mag\n",
    "    batch_df['ps1_g_depth'] = g_depth\n",
    "    batch_df['ps1_r_depth'] = r_depth\n",
    "    batch_df['ps1_i_depth'] = i_depth\n",
    "    batch_df['ps1_g_fwhm'] = g_fwhm\n",
    "    batch_df['ps1_r_fwhm'] = r_fwhm\n",
    "    batch_df['ps1_i_fwhm'] = i_fwhm\n",
    "\n",
    "    # Filter: keep only rows with at least 2 non-null PS1 magnitudes\n",
    "    mask = (\n",
    "        batch_df[['ps1_g_mag', 'ps1_r_mag', 'ps1_i_mag']]\n",
    "        .notnull()\n",
    "        .sum(axis=1) >= 2\n",
    "    )\n",
    "    filtered_df = batch_df[mask].reset_index(drop=True)\n",
    "    print(f\"Filtered from {len(batch_df)} → {len(filtered_df)} rows with ≥ 2 PS1 bands\")\n",
    "    return filtered_df\n",
    "\n",
    "for i in range(0, n_objects, BATCH_SIZE):\n",
    "    batch_num = i // BATCH_SIZE + 1\n",
    "    output_file = os.path.join(OUTPUT_FOLDER, OUTPUT_CSV_TEMPLATE.format(batch_num=batch_num))\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Batch {batch_num} already done (found {output_file}), skipping...\")\n",
    "        continue\n",
    "\n",
    "    batch_df = df.iloc[i:i+BATCH_SIZE].copy()\n",
    "    print(f\"\\nProcessing batch {batch_num} ({i} to {i + len(batch_df) - 1})...\")\n",
    "    filtered_df = query_ps1_batch(batch_df)\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved filtered batch {batch_num} to {output_file}\")\n",
    "\n",
    "print(\"\\nAll batches processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace2f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sdss_lrg_ps1_matched_batch_1.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_10.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_100.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_101.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_102.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_103.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_104.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_105.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_106.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_107.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_108.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_109.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_11.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_110.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_111.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_112.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_113.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_114.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_115.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_116.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_117.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_118.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_12.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_13.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_14.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_15.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_16.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_17.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_18.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_19.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_2.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_20.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_21.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_22.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_23.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_24.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_25.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_26.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_27.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_28.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_29.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_3.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_30.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_31.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_32.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_33.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_34.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_35.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_36.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_37.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_38.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_39.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_4.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_40.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_41.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_42.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_43.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_44.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_45.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_46.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_47.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_48.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_49.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_5.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_50.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_51.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_52.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_53.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_54.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_55.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_56.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_57.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_58.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_59.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_6.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_60.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_61.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_62.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_63.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_64.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_65.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_66.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_67.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_68.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_69.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_7.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_70.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_71.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_72.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_73.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_74.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_75.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_76.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_77.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_78.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_79.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_8.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_80.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_81.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_82.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_83.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_84.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_85.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_86.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_87.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_88.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_89.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_9.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_90.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_91.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_92.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_93.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_94.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_95.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_96.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_97.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_98.csv...\n",
      "Processing sdss_lrg_ps1_matched_batch_99.csv...\n",
      "\n",
      "Saved 857722 qualified cutout targets to qualified_cutout_targets.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = \"sdss_lrg_queried_objects\"\n",
    "CUTOUT_LIST_CSV = \"qualified_cutout_targets.csv\"\n",
    "\n",
    "def gather_cutout_targets(input_folder, output_csv):\n",
    "    cutout_rows = []\n",
    "\n",
    "    for filename in sorted(os.listdir(input_folder)):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Convert \"--\" strings to NaN explicitly if necessary\n",
    "            for col in ['ps1_g_mag', 'ps1_r_mag', 'ps1_i_mag']:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "            # Count how many PS1 magnitudes are valid (not NaN)\n",
    "            df['valid_ps1_mags'] = df[['ps1_g_mag', 'ps1_r_mag', 'ps1_i_mag']].notnull().sum(axis=1)\n",
    "\n",
    "            # Keep only rows with ≥ 2 valid PS1 bands\n",
    "            qualified = df[df['valid_ps1_mags'] >= 2].copy()\n",
    "\n",
    "            # Optional: record which bands are valid\n",
    "            qualified['has_g'] = qualified['ps1_g_mag'].notnull()\n",
    "            qualified['has_r'] = qualified['ps1_r_mag'].notnull()\n",
    "            qualified['has_i'] = qualified['ps1_i_mag'].notnull()\n",
    "\n",
    "            # Append essential info for cutout download\n",
    "            cutout_rows.append(qualified[['specobjid', 'ra', 'dec', 'has_g', 'has_r', 'has_i']])\n",
    "\n",
    "    # Combine and save\n",
    "    all_cutouts = pd.concat(cutout_rows, ignore_index=True)\n",
    "    all_cutouts.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSaved {len(all_cutouts)} qualified cutout targets to {output_csv}\")\n",
    "\n",
    "    # Fix: avoid scientific notation by converting to string\n",
    "    all_cutouts['specobjid'] = all_cutouts['specobjid'].astype(str)\n",
    "    \n",
    "    all_cutouts.to_csv(output_csv, index=False)\n",
    "\n",
    "gather_cutout_targets(\"sdss_lrg_queried_objects\", \"qualified_cutout_targets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
