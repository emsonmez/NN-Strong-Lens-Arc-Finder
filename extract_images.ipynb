{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660bfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.mast import Catalogs\n",
    "from astropy import units as u\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Extract SDSS DR18 LRG Samples using CasJobs\n",
    "# Data listed in dr18_lrg_sample.csv (Sample Size: 1,174,900)\n",
    "# Criteria : \n",
    "\n",
    "# SELECT\n",
    "  # s.specobjid,\n",
    "  # s.z AS redshift,                   \n",
    "  # s.veldisp,\n",
    "  # p.ra, p.dec, p.u, p.g, p.r, p.i, p.modelMag_r,\n",
    "  # s.programname, s.plate, s.fiberid, s.mjd into mydb.LRG_full_catalog from SpecObjAll AS s\n",
    "# JOIN PhotoObjAll AS p ON s.bestobjid = p.objid\n",
    "# WHERE\n",
    "  # s.class = 'GALAXY'\n",
    "  # AND s.z BETWEEN 0.1 AND 0.7\n",
    "  # AND s.veldisp > 0 AND s.veldisp < 500\n",
    "  # AND s.programname IN ('boss', 'eboss')\n",
    "  # AND (p.r - p.i) > 0.5\n",
    "  # AND (p.g - p.r) > 0.7\n",
    "  # AND p.modelMag_r BETWEEN 16 AND 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-match SDSS data with the PS1 catalog\n",
    "\n",
    "BATCH_SIZE = 10000\n",
    "INPUT_CSV = \"sdss_dr18_lrg_sample.csv\"\n",
    "OUTPUT_CSV_TEMPLATE = \"sdss_lrg_ps1_matched_batch_{batch_num}.csv\"\n",
    "OUTPUT_FOLDER = \"sdss_lrg_queried_objects\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "n_objects = len(df)\n",
    "\n",
    "def query_ps1_batch(batch_df):\n",
    "    g_mag, r_mag, i_mag = [], [], []\n",
    "    g_depth, r_depth, i_depth = [], [], []\n",
    "    g_fwhm, r_fwhm, i_fwhm = [], [], []\n",
    "\n",
    "    for _, row in tqdm(batch_df.iterrows(), total=len(batch_df)):\n",
    "        try:\n",
    "            coord = SkyCoord(ra=row['ra'], dec=row['dec'], unit='deg', frame='icrs')\n",
    "            result = Catalogs.query_region(coord, radius=2.5 * u.arcsec, catalog='PanSTARRS', data_release='dr2')\n",
    "            if len(result) > 0:\n",
    "                best = result[0]\n",
    "                g_mag.append(best.get('gMeanPSFMag'))\n",
    "                r_mag.append(best.get('rMeanPSFMag'))\n",
    "                i_mag.append(best.get('iMeanPSFMag'))\n",
    "\n",
    "                g_depth.append(best.get('gMeanDepth'))\n",
    "                r_depth.append(best.get('rMeanDepth'))\n",
    "                i_depth.append(best.get('iMeanDepth'))\n",
    "\n",
    "                g_fwhm.append(best.get('gFWHM'))\n",
    "                r_fwhm.append(best.get('rFWHM'))\n",
    "                i_fwhm.append(best.get('iFWHM'))\n",
    "            else:\n",
    "                g_mag.append(None)\n",
    "                r_mag.append(None)\n",
    "                i_mag.append(None)\n",
    "                g_depth.append(None)\n",
    "                r_depth.append(None)\n",
    "                i_depth.append(None)\n",
    "                g_fwhm.append(None)\n",
    "                r_fwhm.append(None)\n",
    "                i_fwhm.append(None)\n",
    "        except Exception:\n",
    "            g_mag.append(None)\n",
    "            r_mag.append(None)\n",
    "            i_mag.append(None)\n",
    "            g_depth.append(None)\n",
    "            r_depth.append(None)\n",
    "            i_depth.append(None)\n",
    "            g_fwhm.append(None)\n",
    "            r_fwhm.append(None)\n",
    "            i_fwhm.append(None)\n",
    "\n",
    "    batch_df['ps1_g_mag'] = g_mag\n",
    "    batch_df['ps1_r_mag'] = r_mag\n",
    "    batch_df['ps1_i_mag'] = i_mag\n",
    "    batch_df['ps1_g_depth'] = g_depth\n",
    "    batch_df['ps1_r_depth'] = r_depth\n",
    "    batch_df['ps1_i_depth'] = i_depth\n",
    "    batch_df['ps1_g_fwhm'] = g_fwhm\n",
    "    batch_df['ps1_r_fwhm'] = r_fwhm\n",
    "    batch_df['ps1_i_fwhm'] = i_fwhm\n",
    "\n",
    "    # Filter: keep only rows with at least 2 non-null PS1 magnitudes\n",
    "    mask = (\n",
    "        batch_df[['ps1_g_mag', 'ps1_r_mag', 'ps1_i_mag']]\n",
    "        .notnull()\n",
    "        .sum(axis=1) >= 2\n",
    "    )\n",
    "    filtered_df = batch_df[mask].reset_index(drop=True)\n",
    "    print(f\"Filtered from {len(batch_df)} → {len(filtered_df)} rows with ≥ 2 PS1 bands\")\n",
    "    return filtered_df\n",
    "\n",
    "for i in range(0, n_objects, BATCH_SIZE):\n",
    "    batch_num = i // BATCH_SIZE + 1\n",
    "    output_file = os.path.join(OUTPUT_FOLDER, OUTPUT_CSV_TEMPLATE.format(batch_num=batch_num))\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Batch {batch_num} already done (found {output_file}), skipping...\")\n",
    "        continue\n",
    "\n",
    "    batch_df = df.iloc[i:i+BATCH_SIZE].copy()\n",
    "    print(f\"\\nProcessing batch {batch_num} ({i} to {i + len(batch_df) - 1})...\")\n",
    "    filtered_df = query_ps1_batch(batch_df)\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved filtered batch {batch_num} to {output_file}\")\n",
    "\n",
    "print(\"\\nAll batches processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7c50f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_1.csv\n",
      "  Processed chunk with 9998 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_1.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_10.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_10.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_100.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_100.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_101.csv\n",
      "  Processed chunk with 9985 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_101.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_102.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_102.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_103.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_103.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_104.csv\n",
      "  Processed chunk with 9999 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_104.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_105.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_105.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_106.csv\n",
      "  Processed chunk with 9999 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_106.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_107.csv\n",
      "  Processed chunk with 9998 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_107.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_108.csv\n",
      "  Processed chunk with 9999 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_108.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_109.csv\n",
      "  Processed chunk with 9998 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_109.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_11.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_11.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_110.csv\n",
      "  Processed chunk with 9999 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_110.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_111.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_111.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_112.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_112.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_113.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_113.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_114.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_114.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_115.csv\n",
      "  Processed chunk with 9995 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_115.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_116.csv\n",
      "  Processed chunk with 9990 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_116.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_117.csv\n",
      "  Processed chunk with 9998 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_117.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_118.csv\n",
      "  Processed chunk with 4899 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_118.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_12.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_12.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_13.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_13.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_14.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_14.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_15.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_15.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_16.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_16.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_17.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_17.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_18.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_18.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_19.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_19.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_2.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_2.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_20.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_20.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_21.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_21.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_22.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_22.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_23.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_23.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_24.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_24.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_25.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_25.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_26.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_26.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_27.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_27.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_28.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_28.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_29.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_29.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_3.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_3.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_30.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_30.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_31.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_31.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_32.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_32.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_33.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_33.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_34.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_34.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_35.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_35.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_36.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_36.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_37.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_37.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_38.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_38.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_39.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_39.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_4.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_4.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_40.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_40.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_41.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_41.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_42.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_42.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_43.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_43.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_44.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_44.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_45.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_45.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_46.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_46.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_47.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_47.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_48.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_48.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_49.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_49.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_5.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_5.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_50.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_50.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_51.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_51.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_52.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_52.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_53.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_53.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_54.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_54.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_55.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_55.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_56.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_56.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_57.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_57.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_58.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_58.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_59.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_59.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_6.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_6.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_60.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_60.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_61.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_61.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_62.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_62.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_63.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_63.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_64.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_64.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_65.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_65.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_66.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_66.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_67.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_67.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_68.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_68.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_69.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_69.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_7.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_7.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_70.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_70.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_71.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_71.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_72.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_72.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_73.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_73.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_74.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_74.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_75.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_75.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_76.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_76.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_77.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_77.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_78.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_78.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_79.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_79.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_8.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_8.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_80.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_80.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_81.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_81.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_82.csv\n",
      "  Processed chunk with 9985 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_82.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_83.csv\n",
      "  Processed chunk with 9993 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_83.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_84.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_84.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_85.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_85.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_86.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_86.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_87.csv\n",
      "  Processed chunk with 9993 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_87.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_88.csv\n",
      "  Processed chunk with 9998 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_88.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_89.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_89.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_9.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_9.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_90.csv\n",
      "  Processed chunk with 9999 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_90.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_91.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_91.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_92.csv\n",
      "  Processed chunk with 9993 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_92.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_93.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_93.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_94.csv\n",
      "  Processed chunk with 9993 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_94.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_95.csv\n",
      "  Processed chunk with 9988 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_95.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_96.csv\n",
      "  Processed chunk with 9996 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_96.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_97.csv\n",
      "  Processed chunk with 10000 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_97.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_98.csv\n",
      "  Processed chunk with 9994 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_98.csv\n",
      "\n",
      "Processing: sdss_lrg_ps1_matched_batch_99.csv\n",
      "  Processed chunk with 9997 rows\n",
      "Updated file saved: sdss_lrg_ps1_matched_batch_99.csv\n",
      "All CSVs processed with color info added.\n"
     ]
    }
   ],
   "source": [
    "# Calculating color of each object\n",
    "# Prioritize g-r, then r-i, then g-i, then paste them in each csv file \n",
    "\n",
    "INPUT_FOLDER = \"sdss_lrg_queried_objects\"\n",
    "CHUNK_SIZE = 10000\n",
    "\n",
    "def determine_color(row):\n",
    "    g, r, i = row['ps1_g_mag'], row['ps1_r_mag'], row['ps1_i_mag']\n",
    "    if pd.notnull(g) and pd.notnull(r):\n",
    "        row['color_name'] = 'g-r'\n",
    "        row['color_value'] = g - r\n",
    "    elif pd.notnull(r) and pd.notnull(i):\n",
    "        row['color_name'] = 'r-i'\n",
    "        row['color_value'] = r - i\n",
    "    elif pd.notnull(g) and pd.notnull(i):\n",
    "        row['color_name'] = 'g-i'\n",
    "        row['color_value'] = g - i\n",
    "    else:\n",
    "        row['color_name'] = None\n",
    "        row['color_value'] = None\n",
    "    return row\n",
    "\n",
    "for filename in sorted(os.listdir(INPUT_FOLDER)):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(INPUT_FOLDER, filename)\n",
    "    temp_output_path = os.path.join(INPUT_FOLDER, f\"temp_{filename}\")\n",
    "    first_batch = True\n",
    "\n",
    "    print(f\"\\nProcessing: {filename}\")\n",
    "\n",
    "    for chunk in pd.read_csv(input_path, chunksize=CHUNK_SIZE):\n",
    "        # Replace '--' with NaN and convert to float\n",
    "        for col in ['ps1_g_mag', 'ps1_r_mag', 'ps1_i_mag']:\n",
    "            if col in chunk.columns:\n",
    "                chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
    "\n",
    "        # Apply color computation\n",
    "        chunk = chunk.apply(determine_color, axis=1)\n",
    "\n",
    "        # Save to temp file\n",
    "        chunk.to_csv(\n",
    "            temp_output_path,\n",
    "            mode='w' if first_batch else 'a',\n",
    "            index=False,\n",
    "            header=first_batch\n",
    "        )\n",
    "        first_batch = False\n",
    "        print(f\"  Processed chunk with {len(chunk)} rows\")\n",
    "\n",
    "    # Overwrite original file\n",
    "    os.replace(temp_output_path, input_path)\n",
    "    print(f\"Updated file saved: {filename}\")\n",
    "\n",
    "print(\"All CSVs processed with color info added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve image list: Expecting value: line 1 column 1 (char 0)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Downloading the PS1 cutouts for each object\n",
    "# FITS images in ps1_cutouts for each valid magnitude \n",
    "\n",
    "def ps1_image_list(ra, dec, size=240, filters=\"gri\"):\n",
    "    \"\"\"\n",
    "    Python version of ps1_image_list(): queries the Pan-STARRS image cutouts for available images.\n",
    "\n",
    "    :param ra: Right Ascension in degrees\n",
    "    :param dec: Declination in degrees\n",
    "    :param size: Size in pixels (0.25 arcsec/pix)\n",
    "    :param filters: Filter string, e.g., \"grz\"\n",
    "    :return: DataFrame of available image files\n",
    "    \"\"\"\n",
    "    url = \"https://ps1images.stsci.edu/cgi-bin/ps1cutouts\"\n",
    "    params = {\n",
    "        \"pos\": f\"{ra},{dec}\",\n",
    "        \"filter\": filters,\n",
    "        \"filetypes\": \"stack\",\n",
    "        \"size\": size,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve image list: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage for your object:\n",
    "ra = 212.049238443347\n",
    "dec = -1.19128574956158\n",
    "filters = \"gri\"\n",
    "\n",
    "df = ps1_image_list(ra, dec, size=240, filters=filters)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
